{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c6f7183",
   "metadata": {
    "papermill": {
     "duration": 0.00684,
     "end_time": "2022-09-10T04:10:35.603768",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.596928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# RAPIDS SVR - CV 0.450 - LB 0.44x !!\n",
    "\n",
    "This notebook uses code and ideas from Noufal's great notebook [here][1]. In his notebook he extracts 1 NLP transformer embeddings and trains Sklearn's multioutput regressor + gradient boosting regressor on CPU with 5-Folds.\n",
    "\n",
    "In this notebook, we use [RAPIDS SVR][3] to train and predict. Since [RAPIDS cuML's SVR][3] uses GPU it is very fast. This allows us to train with more extracted embeddings quickly and more folds. In this notebook, we use 25-Folds! And in this notebook, we extract embeddings from 5 NLP transformers. Afterward we concatenate them and have 6000 columns of features! [RAPIDS SVR][3] has built in feature reduction, so it learns to use the most informative features from all the NLP transformers!\n",
    "\n",
    "![](https://raw.githubusercontent.com/cdeotte/Kaggle_Images/main/Sep-2022/svr.png)\n",
    "\n",
    "Note that we do not finetune the NLP transformers. The Deberta transformers in this notebook are the same pretrained transformers that we download from Hugging Face. They have not been finetuned on Kaggle's competition data. This demonstrates that pretrained models already come with intelligence.\n",
    "\n",
    "This is similar to Giba's 1st place solution in Kaggle's Pet Competition [here][2]. That competition was computer vision regression. Giba extracted embeddings from dozens of image CNN's and image transformers. The models were pretrained (most likely on ImageNet data) but not finetuned (on Kaggle competition data). He concatenated the embeddings and trained a [RAPIDS SVR][3] on tens of thousands of feature columns!\n",
    "\n",
    "[1]: https://www.kaggle.com/code/kvsnoufal/lb0-46-gb-debertaembedding\n",
    "[2]: https://www.kaggle.com/competitions/petfinder-pawpularity-score/discussion/301686\n",
    "[3]: https://docs.rapids.ai/api/cuml/stable/api.html#support-vector-machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a82b62c",
   "metadata": {
    "papermill": {
     "duration": 0.005405,
     "end_time": "2022-09-10T04:10:35.614972",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.609567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Load Libraries and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3670fd1b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:35.627840Z",
     "iopub.status.busy": "2022-09-10T04:10:35.627363Z",
     "iopub.status.idle": "2022-09-10T04:10:35.637736Z",
     "shell.execute_reply": "2022-09-10T04:10:35.636901Z"
    },
    "papermill": {
     "duration": 0.019292,
     "end_time": "2022-09-10T04:10:35.639745",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.620453",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os, gc, re, warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84747694",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:35.651835Z",
     "iopub.status.busy": "2022-09-10T04:10:35.651561Z",
     "iopub.status.idle": "2022-09-10T04:10:35.846526Z",
     "shell.execute_reply": "2022-09-10T04:10:35.845459Z"
    },
    "papermill": {
     "duration": 0.204385,
     "end_time": "2022-09-10T04:10:35.849631",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.645246",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (3911, 9) Test shape: (3, 3) Test columns: Index(['text_id', 'full_text', 'src'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>full_text</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "      <th>src</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0016926B079C</td>\n",
       "      <td>I think that students would benefit from learn...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0022683E9EA5</td>\n",
       "      <td>When a problem is a change you have to let it ...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00299B378633</td>\n",
       "      <td>Dear, Principal\\n\\nIf u change the school poli...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003885A45F42</td>\n",
       "      <td>The best time in life is when you become yours...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.5</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0049B1DF5CCC</td>\n",
       "      <td>Small act of kindness can impact in other peop...</td>\n",
       "      <td>2.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2.5</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id                                          full_text  cohesion  \\\n",
       "0  0016926B079C  I think that students would benefit from learn...       3.5   \n",
       "1  0022683E9EA5  When a problem is a change you have to let it ...       2.5   \n",
       "2  00299B378633  Dear, Principal\\n\\nIf u change the school poli...       3.0   \n",
       "3  003885A45F42  The best time in life is when you become yours...       4.5   \n",
       "4  0049B1DF5CCC  Small act of kindness can impact in other peop...       2.5   \n",
       "\n",
       "   syntax  vocabulary  phraseology  grammar  conventions    src  \n",
       "0     3.5         3.0          3.0      4.0          3.0  train  \n",
       "1     2.5         3.0          2.0      2.0          2.5  train  \n",
       "2     3.5         3.0          3.0      3.0          2.5  train  \n",
       "3     4.5         4.5          4.5      4.0          5.0  train  \n",
       "4     3.0         3.0          3.0      2.5          2.5  train  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dftr = pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/train.csv\")\n",
    "dftr[\"src\"]=\"train\"\n",
    "dfte = pd.read_csv(\"/kaggle/input/feedback-prize-english-language-learning/test.csv\")\n",
    "dfte[\"src\"]=\"test\"\n",
    "print('Train shape:',dftr.shape,'Test shape:',dfte.shape,'Test columns:',dfte.columns)\n",
    "df = pd.concat([dftr,dfte],ignore_index=True)\n",
    "\n",
    "dftr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7552234a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:35.863427Z",
     "iopub.status.busy": "2022-09-10T04:10:35.863113Z",
     "iopub.status.idle": "2022-09-10T04:10:35.867911Z",
     "shell.execute_reply": "2022-09-10T04:10:35.866930Z"
    },
    "papermill": {
     "duration": 0.014067,
     "end_time": "2022-09-10T04:10:35.870015",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.855948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "target_cols = ['cohesion', 'syntax', 'vocabulary', 'phraseology', 'grammar', 'conventions',]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a88f9fd",
   "metadata": {
    "papermill": {
     "duration": 0.006037,
     "end_time": "2022-09-10T04:10:35.882275",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.876238",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Make 25 Stratified Folds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7965cad9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:35.895692Z",
     "iopub.status.busy": "2022-09-10T04:10:35.895408Z",
     "iopub.status.idle": "2022-09-10T04:10:36.969694Z",
     "shell.execute_reply": "2022-09-10T04:10:36.967639Z"
    },
    "papermill": {
     "duration": 1.084145,
     "end_time": "2022-09-10T04:10:36.972601",
     "exception": false,
     "start_time": "2022-09-10T04:10:35.888456",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples per fold:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11.0    157\n",
       "21.0    157\n",
       "1.0     157\n",
       "7.0     157\n",
       "20.0    157\n",
       "14.0    157\n",
       "19.0    157\n",
       "12.0    157\n",
       "23.0    157\n",
       "3.0     157\n",
       "6.0     157\n",
       "5.0     156\n",
       "13.0    156\n",
       "22.0    156\n",
       "0.0     156\n",
       "15.0    156\n",
       "24.0    156\n",
       "17.0    156\n",
       "9.0     156\n",
       "8.0     156\n",
       "4.0     156\n",
       "2.0     156\n",
       "18.0    156\n",
       "10.0    156\n",
       "16.0    156\n",
       "Name: FOLD, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('../input/iterativestratification')\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "FOLDS = 25\n",
    "skf = MultilabelStratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=42)\n",
    "for i,(train_index, val_index) in enumerate(skf.split(dftr,dftr[target_cols])):\n",
    "    dftr.loc[val_index,'FOLD'] = i\n",
    "print('Train samples per fold:')\n",
    "dftr.FOLD.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "824a664b",
   "metadata": {
    "papermill": {
     "duration": 0.007483,
     "end_time": "2022-09-10T04:10:36.986851",
     "exception": false,
     "start_time": "2022-09-10T04:10:36.979368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Generate Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a1ceb295",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:37.001303Z",
     "iopub.status.busy": "2022-09-10T04:10:36.999875Z",
     "iopub.status.idle": "2022-09-10T04:10:39.041082Z",
     "shell.execute_reply": "2022-09-10T04:10:39.039899Z"
    },
    "papermill": {
     "duration": 2.050718,
     "end_time": "2022-09-10T04:10:39.043658",
     "exception": false,
     "start_time": "2022-09-10T04:10:36.992940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModel,AutoTokenizer\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "07a37402",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:39.059936Z",
     "iopub.status.busy": "2022-09-10T04:10:39.059470Z",
     "iopub.status.idle": "2022-09-10T04:10:39.065690Z",
     "shell.execute_reply": "2022-09-10T04:10:39.064675Z"
    },
    "papermill": {
     "duration": 0.016823,
     "end_time": "2022-09-10T04:10:39.068031",
     "exception": false,
     "start_time": "2022-09-10T04:10:39.051208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state.detach().cpu()\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a434bc4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:39.082028Z",
     "iopub.status.busy": "2022-09-10T04:10:39.081634Z",
     "iopub.status.idle": "2022-09-10T04:10:39.092625Z",
     "shell.execute_reply": "2022-09-10T04:10:39.091710Z"
    },
    "papermill": {
     "duration": 0.020546,
     "end_time": "2022-09-10T04:10:39.094997",
     "exception": false,
     "start_time": "2022-09-10T04:10:39.074451",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "class EmbedDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,df):\n",
    "        self.df = df.reset_index(drop=True)\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        text = self.df.loc[idx,\"full_text\"]\n",
    "        tokens = tokenizer(\n",
    "                text,\n",
    "                None,\n",
    "                add_special_tokens=True,\n",
    "                padding='max_length',\n",
    "                truncation=True,\n",
    "                max_length=MAX_LEN,return_tensors=\"pt\")\n",
    "        tokens = {k:v.squeeze(0) for k,v in tokens.items()}\n",
    "        return tokens\n",
    "\n",
    "ds_tr = EmbedDataset(dftr)\n",
    "embed_dataloader_tr = torch.utils.data.DataLoader(ds_tr,\\\n",
    "                        batch_size=BATCH_SIZE,\\\n",
    "                        shuffle=False)\n",
    "ds_te = EmbedDataset(dfte)\n",
    "embed_dataloader_te = torch.utils.data.DataLoader(ds_te,\\\n",
    "                        batch_size=BATCH_SIZE,\\\n",
    "                        shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a32e1a",
   "metadata": {
    "papermill": {
     "duration": 0.006111,
     "end_time": "2022-09-10T04:10:39.107492",
     "exception": false,
     "start_time": "2022-09-10T04:10:39.101381",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Extract Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "082ce818",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:39.123076Z",
     "iopub.status.busy": "2022-09-10T04:10:39.122285Z",
     "iopub.status.idle": "2022-09-10T04:10:39.134653Z",
     "shell.execute_reply": "2022-09-10T04:10:39.133659Z"
    },
    "papermill": {
     "duration": 0.022958,
     "end_time": "2022-09-10T04:10:39.137111",
     "exception": false,
     "start_time": "2022-09-10T04:10:39.114153",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = None\n",
    "MAX_LEN = 640\n",
    "\n",
    "def get_embeddings(MODEL_NM='', MAX=640, BATCH_SIZE=4, verbose=True):\n",
    "    global tokenizer, MAX_LEN\n",
    "    DEVICE=\"cuda\"\n",
    "    model = AutoModel.from_pretrained( MODEL_NM )\n",
    "    tokenizer = AutoTokenizer.from_pretrained( MODEL_NM )\n",
    "    MAX_LEN = MAX\n",
    "    \n",
    "    model = model.to(DEVICE)\n",
    "    model.eval()\n",
    "    all_train_text_feats = []\n",
    "    for batch in tqdm(embed_dataloader_tr,total=len(embed_dataloader_tr)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n",
    "        # Normalize the embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n",
    "        all_train_text_feats.extend(sentence_embeddings)\n",
    "    all_train_text_feats = np.array(all_train_text_feats)\n",
    "    if verbose:\n",
    "        print('Train embeddings shape',all_train_text_feats.shape)\n",
    "        \n",
    "    te_text_feats = []\n",
    "    for batch in tqdm(embed_dataloader_te,total=len(embed_dataloader_te)):\n",
    "        input_ids = batch[\"input_ids\"].to(DEVICE)\n",
    "        attention_mask = batch[\"attention_mask\"].to(DEVICE)\n",
    "        with torch.no_grad():\n",
    "            model_output = model(input_ids=input_ids,attention_mask=attention_mask)\n",
    "        sentence_embeddings = mean_pooling(model_output, attention_mask.detach().cpu())\n",
    "        # Normalize the embeddings\n",
    "        sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "        sentence_embeddings =  sentence_embeddings.squeeze(0).detach().cpu().numpy()\n",
    "        te_text_feats.extend(sentence_embeddings)\n",
    "    te_text_feats = np.array(te_text_feats)\n",
    "    if verbose:\n",
    "        print('Test embeddings shape',te_text_feats.shape)\n",
    "        \n",
    "    return all_train_text_feats, te_text_feats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49a7087d",
   "metadata": {
    "papermill": {
     "duration": 0.006143,
     "end_time": "2022-09-10T04:10:39.149926",
     "exception": false,
     "start_time": "2022-09-10T04:10:39.143783",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get Base Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "07f2b3b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:10:39.163635Z",
     "iopub.status.busy": "2022-09-10T04:10:39.163372Z",
     "iopub.status.idle": "2022-09-10T04:13:53.906369Z",
     "shell.execute_reply": "2022-09-10T04:13:53.903971Z"
    },
    "papermill": {
     "duration": 194.752857,
     "end_time": "2022-09-10T04:13:53.909078",
     "exception": false,
     "start_time": "2022-09-10T04:10:39.156221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-base/deberta-base were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'config', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 978/978 [03:02<00:00,  5.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape (3911, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  7.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape (3, 768)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NM = '../input/huggingface-deberta-variants/deberta-base/deberta-base'\n",
    "all_train_text_feats, te_text_feats = get_embeddings(MODEL_NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fcd2fd",
   "metadata": {
    "papermill": {
     "duration": 0.054602,
     "end_time": "2022-09-10T04:13:54.019204",
     "exception": false,
     "start_time": "2022-09-10T04:13:53.964602",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get Large V3 Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a982c91a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:13:54.131553Z",
     "iopub.status.busy": "2022-09-10T04:13:54.131207Z",
     "iopub.status.idle": "2022-09-10T04:22:15.994084Z",
     "shell.execute_reply": "2022-09-10T04:22:15.992907Z"
    },
    "papermill": {
     "duration": 501.923105,
     "end_time": "2022-09-10T04:22:15.998439",
     "exception": false,
     "start_time": "2022-09-10T04:13:54.075334",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/deberta-v3-large/deberta-v3-large were not used when initializing DebertaV2Model: ['mask_predictions.classifier.weight', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.bias', 'mask_predictions.classifier.bias', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.dense.weight']\n",
      "- This IS expected if you are initializing DebertaV2Model from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaV2Model from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "100%|██████████| 978/978 [08:06<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape (3911, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape (3, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NM = '../input/deberta-v3-large/deberta-v3-large'\n",
    "all_train_text_feats2, te_text_feats2 = get_embeddings(MODEL_NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad57dbe6",
   "metadata": {
    "papermill": {
     "duration": 0.102248,
     "end_time": "2022-09-10T04:22:16.208477",
     "exception": false,
     "start_time": "2022-09-10T04:22:16.106229",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get Large Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8da96b7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:22:16.428171Z",
     "iopub.status.busy": "2022-09-10T04:22:16.427825Z",
     "iopub.status.idle": "2022-09-10T04:30:42.494091Z",
     "shell.execute_reply": "2022-09-10T04:30:42.492763Z"
    },
    "papermill": {
     "duration": 506.185707,
     "end_time": "2022-09-10T04:30:42.498069",
     "exception": false,
     "start_time": "2022-09-10T04:22:16.312362",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-large/deberta-large were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'config', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 978/978 [08:06<00:00,  2.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape (3911, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  2.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape (3, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NM = '../input/huggingface-deberta-variants/deberta-large/deberta-large'\n",
    "all_train_text_feats3, te_text_feats3 = get_embeddings(MODEL_NM)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb055b07",
   "metadata": {
    "papermill": {
     "duration": 0.151466,
     "end_time": "2022-09-10T04:30:42.803019",
     "exception": false,
     "start_time": "2022-09-10T04:30:42.651553",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get Large MNLI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cdbe4db2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:30:43.151526Z",
     "iopub.status.busy": "2022-09-10T04:30:43.151166Z",
     "iopub.status.idle": "2022-09-10T04:37:24.453055Z",
     "shell.execute_reply": "2022-09-10T04:37:24.451884Z"
    },
    "papermill": {
     "duration": 401.504869,
     "end_time": "2022-09-10T04:37:24.458543",
     "exception": false,
     "start_time": "2022-09-10T04:30:42.953674",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli were not used when initializing DebertaModel: ['config', 'classifier.weight', 'classifier.bias', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 978/978 [06:22<00:00,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape (3911, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  3.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape (3, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NM = '../input/huggingface-deberta-variants/deberta-large-mnli/deberta-large-mnli'\n",
    "all_train_text_feats4, te_text_feats4 = get_embeddings(MODEL_NM, MAX=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2aae42",
   "metadata": {
    "papermill": {
     "duration": 0.260503,
     "end_time": "2022-09-10T04:37:25.030924",
     "exception": false,
     "start_time": "2022-09-10T04:37:24.770421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Get XLarge Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "709d9784",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:37:25.431815Z",
     "iopub.status.busy": "2022-09-10T04:37:25.431449Z",
     "iopub.status.idle": "2022-09-10T04:50:14.703426Z",
     "shell.execute_reply": "2022-09-10T04:50:14.702518Z"
    },
    "papermill": {
     "duration": 769.47374,
     "end_time": "2022-09-10T04:50:14.705979",
     "exception": false,
     "start_time": "2022-09-10T04:37:25.232239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at ../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge were not used when initializing DebertaModel: ['lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.weight', 'lm_predictions.lm_head.dense.bias']\n",
      "- This IS expected if you are initializing DebertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "100%|██████████| 978/978 [12:26<00:00,  1.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train embeddings shape (3911, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test embeddings shape (3, 1024)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_NM = '../input/huggingface-deberta-variants/deberta-xlarge/deberta-xlarge'\n",
    "all_train_text_feats5, te_text_feats5 = get_embeddings(MODEL_NM, MAX=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7345390a",
   "metadata": {
    "papermill": {
     "duration": 0.247107,
     "end_time": "2022-09-10T04:50:15.343807",
     "exception": false,
     "start_time": "2022-09-10T04:50:15.096700",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Combine Feature Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678c2bd4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:50:15.839495Z",
     "iopub.status.busy": "2022-09-10T04:50:15.839138Z",
     "iopub.status.idle": "2022-09-10T04:50:16.044835Z",
     "shell.execute_reply": "2022-09-10T04:50:16.043730Z"
    },
    "papermill": {
     "duration": 0.457385,
     "end_time": "2022-09-10T04:50:16.047909",
     "exception": false,
     "start_time": "2022-09-10T04:50:15.590524",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our concatenated embeddings have shape (3911, 4864)\n"
     ]
    }
   ],
   "source": [
    "all_train_text_feats = np.concatenate([all_train_text_feats,all_train_text_feats2,\n",
    "                                       all_train_text_feats3,all_train_text_feats4,\n",
    "                                       all_train_text_feats5],axis=1)\n",
    "\n",
    "te_text_feats = np.concatenate([te_text_feats,te_text_feats2,\n",
    "                                te_text_feats3,te_text_feats4,\n",
    "                                te_text_feats5],axis=1)\n",
    "\n",
    "del all_train_text_feats2, te_text_feats2\n",
    "del all_train_text_feats3, te_text_feats3\n",
    "del all_train_text_feats4, te_text_feats4\n",
    "del all_train_text_feats5, te_text_feats5\n",
    "gc.collect()\n",
    "\n",
    "print('Our concatenated embeddings have shape', all_train_text_feats.shape )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c4b3e",
   "metadata": {
    "papermill": {
     "duration": 0.264229,
     "end_time": "2022-09-10T04:50:16.564156",
     "exception": false,
     "start_time": "2022-09-10T04:50:16.299927",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Train RAPIDS cuML SVR\n",
    "Documentation for RAPIDS SVM is [here][1]\n",
    "\n",
    "[1]: https://docs.rapids.ai/api/cuml/stable/api.html#support-vector-machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38bc3009",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:50:17.119701Z",
     "iopub.status.busy": "2022-09-10T04:50:17.119340Z",
     "iopub.status.idle": "2022-09-10T04:50:20.092374Z",
     "shell.execute_reply": "2022-09-10T04:50:20.091387Z"
    },
    "papermill": {
     "duration": 3.271607,
     "end_time": "2022-09-10T04:50:20.094636",
     "exception": false,
     "start_time": "2022-09-10T04:50:16.823029",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAPIDS version 21.10.02\n"
     ]
    }
   ],
   "source": [
    "from cuml.svm import SVR\n",
    "import cuml\n",
    "print('RAPIDS version',cuml.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea265113",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:50:20.592903Z",
     "iopub.status.busy": "2022-09-10T04:50:20.592535Z",
     "iopub.status.idle": "2022-09-10T04:50:59.671510Z",
     "shell.execute_reply": "2022-09-10T04:50:59.670401Z"
    },
    "papermill": {
     "duration": 39.329447,
     "end_time": "2022-09-10T04:50:59.673871",
     "exception": false,
     "start_time": "2022-09-10T04:50:20.344424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 0 RSME score: 0.45941574428793963\n",
      "#########################\n",
      "### Fold 2\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 1 RSME score: 0.44688430931942386\n",
      "#########################\n",
      "### Fold 3\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 2 RSME score: 0.4599025031310042\n",
      "#########################\n",
      "### Fold 4\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 3 RSME score: 0.44741512751324436\n",
      "#########################\n",
      "### Fold 5\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 4 RSME score: 0.45173666632901305\n",
      "#########################\n",
      "### Fold 6\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 5 RSME score: 0.43841645457942424\n",
      "#########################\n",
      "### Fold 7\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 6 RSME score: 0.44002583378008825\n",
      "#########################\n",
      "### Fold 8\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 7 RSME score: 0.46425273184949556\n",
      "#########################\n",
      "### Fold 9\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 8 RSME score: 0.44110534277046565\n",
      "#########################\n",
      "### Fold 10\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 9 RSME score: 0.48287765576941793\n",
      "#########################\n",
      "### Fold 11\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 10 RSME score: 0.4415879581103807\n",
      "#########################\n",
      "### Fold 12\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 11 RSME score: 0.44379393586269034\n",
      "#########################\n",
      "### Fold 13\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 12 RSME score: 0.4648990523266094\n",
      "#########################\n",
      "### Fold 14\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 13 RSME score: 0.4321389569195541\n",
      "#########################\n",
      "### Fold 15\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 14 RSME score: 0.4622129807094828\n",
      "#########################\n",
      "### Fold 16\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 15 RSME score: 0.43682152405557734\n",
      "#########################\n",
      "### Fold 17\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 16 RSME score: 0.4290582727989909\n",
      "#########################\n",
      "### Fold 18\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 17 RSME score: 0.45875548968884866\n",
      "#########################\n",
      "### Fold 19\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 18 RSME score: 0.45930239661531264\n",
      "#########################\n",
      "### Fold 20\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 19 RSME score: 0.4302133278495868\n",
      "#########################\n",
      "### Fold 21\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 20 RSME score: 0.4668647060103512\n",
      "#########################\n",
      "### Fold 22\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 21 RSME score: 0.4626324647262852\n",
      "#########################\n",
      "### Fold 23\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 22 RSME score: 0.45424023616958714\n",
      "#########################\n",
      "### Fold 24\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 23 RSME score: 0.45986534124011685\n",
      "#########################\n",
      "### Fold 25\n",
      "#########################\n",
      "cohesion , syntax , vocabulary , phraseology , grammar , conventions , \n",
      "Fold : 24 RSME score: 0.43017786744876757\n",
      "#########################\n",
      "Overall CV RSME = 0.45058387519446635\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "preds = []\n",
    "scores = []\n",
    "def comp_score(y_true,y_pred):\n",
    "    rmse_scores = []\n",
    "    for i in range(len(target_cols)):\n",
    "        rmse_scores.append(np.sqrt(mean_squared_error(y_true[:,i],y_pred[:,i])))\n",
    "    return np.mean(rmse_scores)\n",
    "\n",
    "#for fold in tqdm(range(FOLDS),total=FOLDS):\n",
    "for fold in range(FOLDS):\n",
    "    print('#'*25)\n",
    "    print('### Fold',fold+1)\n",
    "    print('#'*25)\n",
    "    \n",
    "    dftr_ = dftr[dftr[\"FOLD\"]!=fold]\n",
    "    dfev_ = dftr[dftr[\"FOLD\"]==fold]\n",
    "    \n",
    "    tr_text_feats = all_train_text_feats[list(dftr_.index),:]\n",
    "    ev_text_feats = all_train_text_feats[list(dfev_.index),:]\n",
    "    \n",
    "    ev_preds = np.zeros((len(ev_text_feats),6))\n",
    "    test_preds = np.zeros((len(te_text_feats),6))\n",
    "    for i,t in enumerate(target_cols):\n",
    "        print(t,', ',end='')\n",
    "        clf = SVR(C=1)\n",
    "        clf.fit(tr_text_feats, dftr_[t].values)\n",
    "        ev_preds[:,i] = clf.predict(ev_text_feats)\n",
    "        test_preds[:,i] = clf.predict(te_text_feats)\n",
    "    print()\n",
    "    score = comp_score(dfev_[target_cols].values,ev_preds)\n",
    "    scores.append(score)\n",
    "    print(\"Fold : {} RSME score: {}\".format(fold,score))\n",
    "    preds.append(test_preds)\n",
    "    \n",
    "print('#'*25)\n",
    "print('Overall CV RSME =',np.mean(scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "596fa282",
   "metadata": {
    "papermill": {
     "duration": 0.266649,
     "end_time": "2022-09-10T04:51:00.206693",
     "exception": false,
     "start_time": "2022-09-10T04:50:59.940044",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Overall CV Score 0.4505\n",
    "Wow, nice! Our overall CV score using RAPIDS SVR without training any NLP transformers is 0.4505! And our LB is 0.44x!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88dd1e47",
   "metadata": {
    "papermill": {
     "duration": 0.255895,
     "end_time": "2022-09-10T04:51:00.766596",
     "exception": false,
     "start_time": "2022-09-10T04:51:00.510701",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Create Submission CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "013e6e81",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:51:01.280269Z",
     "iopub.status.busy": "2022-09-10T04:51:01.279917Z",
     "iopub.status.idle": "2022-09-10T04:51:01.298538Z",
     "shell.execute_reply": "2022-09-10T04:51:01.297644Z"
    },
    "papermill": {
     "duration": 0.276856,
     "end_time": "2022-09-10T04:51:01.300868",
     "exception": false,
     "start_time": "2022-09-10T04:51:01.024012",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sub = dfte.copy()\n",
    "\n",
    "sub.loc[:,target_cols] = np.average(np.array(preds),axis=0) #,weights=[1/s for s in scores]\n",
    "sub_columns = pd.read_csv(\"../input/feedback-prize-english-language-learning/sample_submission.csv\").columns\n",
    "sub = sub[sub_columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0dc9da4f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-10T04:51:01.859109Z",
     "iopub.status.busy": "2022-09-10T04:51:01.858695Z",
     "iopub.status.idle": "2022-09-10T04:51:01.875744Z",
     "shell.execute_reply": "2022-09-10T04:51:01.874263Z"
    },
    "papermill": {
     "duration": 0.321635,
     "end_time": "2022-09-10T04:51:01.878410",
     "exception": false,
     "start_time": "2022-09-10T04:51:01.556775",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_id</th>\n",
       "      <th>cohesion</th>\n",
       "      <th>syntax</th>\n",
       "      <th>vocabulary</th>\n",
       "      <th>phraseology</th>\n",
       "      <th>grammar</th>\n",
       "      <th>conventions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000C359D63E</td>\n",
       "      <td>2.920062</td>\n",
       "      <td>2.798517</td>\n",
       "      <td>3.135469</td>\n",
       "      <td>2.941101</td>\n",
       "      <td>2.661195</td>\n",
       "      <td>2.668508</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000BAD50D026</td>\n",
       "      <td>2.688524</td>\n",
       "      <td>2.443526</td>\n",
       "      <td>2.692254</td>\n",
       "      <td>2.304748</td>\n",
       "      <td>2.013087</td>\n",
       "      <td>2.642344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00367BB2546B</td>\n",
       "      <td>3.648225</td>\n",
       "      <td>3.471449</td>\n",
       "      <td>3.584720</td>\n",
       "      <td>3.656427</td>\n",
       "      <td>3.407419</td>\n",
       "      <td>3.358812</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        text_id  cohesion    syntax  vocabulary  phraseology   grammar  \\\n",
       "0  0000C359D63E  2.920062  2.798517    3.135469     2.941101  2.661195   \n",
       "1  000BAD50D026  2.688524  2.443526    2.692254     2.304748  2.013087   \n",
       "2  00367BB2546B  3.648225  3.471449    3.584720     3.656427  3.407419   \n",
       "\n",
       "   conventions  \n",
       "0     2.668508  \n",
       "1     2.642344  \n",
       "2     3.358812  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub.to_csv(\"submission.csv\",index=None)\n",
    "sub.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2437.583821,
   "end_time": "2022-09-10T04:51:05.260170",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-09-10T04:10:27.676349",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
